name: Generate Threads RSS

on:
  schedule:
    # 建議改為每小時的隨機分鐘執行（例如 17分），避開整點高峰期，GitHub Actions 會跑得更快
    - cron: '17 * * * *'
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        cache: 'pip' # 自動快取 pip 套件

    - name: Install dependencies
      run: |
        pip install jmespath parsel nested_lookup playwright rfeed
    
    # 關鍵優化：快取 Playwright 瀏覽器，避免每次都重新下載
    - name: Cache Playwright Browsers
      id: playwright-cache
      uses: actions/cache@v4
      with:
        path: ~/.cache/ms-playwright
        key: ${{ runner.os }}-playwright-${{ hashFiles('**/requirements.txt') }}

    - name: Install Playwright Chromium
      if: steps.playwright-cache.outputs.cache-hit != 'true'
      run: playwright install chromium --with-deps

    - name: Install Playwright dependencies (if cache hit)
      if: steps.playwright-cache.outputs.cache-hit == 'true'
      run: playwright install-deps chromium

    - name: Run Scraper
      run: |
        mkdir -p public
        # 建立一個簡單的 index.html 並列出所有 feed
        echo "<html><body><h1>Threads RSS Feeds</h1><ul><li><a href='threads_feed.xml'>@prompt_case Feed</a></li></ul></body></html>" > public/index.html
        
        # 執行抓取 (確保使用 threads.net 而非 threads.com，後者有時會跳轉)
        python scraper.py https://www.threads.net public/threads_feed.xml
      
    - name: Upload artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: public

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
